---
---

@string{aps = {American Physical Society,}}

#author_version add this tag for url
#publisher_version add this tag for url, add comming_soon if proceeding yet to happen

@misc{https://doi.org/10.48550/arxiv.2110.07674,
  doi = {10.48550/ARXIV.2110.07674},
  url = {https://arxiv.org/abs/2110.07674},
  author = {Gera, Pulkit and KT, Aakash and Dhawal, Sirikonda and Sakurikar, Parikshit and Narayanan, P. J.},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Appearance Editing with Free-viewpoint Neural Rendering},
  abstract = {We present a neural rendering framework for simultaneous view synthesis and appearance editing of a scene from multi-view images captured under known environment illumination. Existing approaches either achieve view synthesis alone or view synthesis along with relighting, without direct control over the scene's appearance. Our approach explicitly disentangles the appearance and learns a lighting representation that is independent of it. Specifically, we independently estimate the BRDF and use it to learn a lighting-only representation of the scene. Such disentanglement allows our approach to generalize to arbitrary changes in appearance while performing view synthesis. We show results of editing the appearance of a real scene, demonstrating that our approach produces plausible appearance editing. The performance of our view synthesis approach is demonstrated to be at par with state-of-the-art approaches on both real and synthetic data.},
  publisher = {arXiv},
  year = {2021},
  website={https://darthgera123.github.io/appearance-editing/},
  copyright = {Creative Commons Attribution 4.0 International},
  author_version = {https://arxiv.org/abs/2110.07674},
  conference = {ICVGIP 2021},
  publisher_version = {https://dl.acm.org/doi/abs/10.1145/3490035.3490299},
  selected={true}
}

@misc{https://doi.org/10.48550/arxiv.2203.12399,
  doi = {10.48550/ARXIV.2203.12399},
  url = {https://arxiv.org/abs/2203.12399},
  author = {Dhawal, Sirikonda and KT, Aakash and Narayanan, P. J.},
  keywords = {Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {PRTT: Precomputed Radiance Transfer Textures},
  publisher = {arXiv},
  abstract = {Precomputed Radiance Transfer (PRT) can achieve high quality renders of glossy materials at real-time framerates. PRT involves precomputing a k-dimensional transfer vector of Spherical Harmonic (SH) coefficients at specific points for a scene. Most prior art precomputes transfer at vertices of the mesh and interpolates color for interior points. They require finer mesh tessellations for high quality renderings. In this paper, we explore and present the use of textures for storing transfer. Using transfer textures decouples mesh resolution from transfer storage and sampling which is useful especially for glossy renders. We further demonstrate glossy inter-reflections by precomputing additional textures. We thoroughly discuss practical aspects of transfer textures and analyze their performance in real-time rendering applications. We show equivalent or higher render quality and FPS and demonstrate results on several challenging scenes.},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  author_version = {https://arxiv.org/abs/2203.12399},
  publisher_version = {comming_soon},
  conference = {EG 2022-Poster},
  selected={true}
}
