---
---

@string{aps = {American Physical Society,}}

@inproceedings{tavares_d2rcrime:_2012,
	address = {Fairfax, VA},
	title = {{D2RCrime}: {A} {Tool} for {Helping} to {Publish} {Crime} {Reports} on the {Web} from {Relational} {Data}},
	shorttitle = {{D2RCrime}},
	abstract = {In the Law Enforcement context, more and more data about crime occurrences are becoming available to the general public. For an effective use of open data, it is desirable that the different sources of information follow a pattern, which allows reliable comparisons. In addition, it is expected that the task of creating a correspondence between the pattern and the internal representations of each source of information is not a steep learning curve. These two conditions are hardly found in the actual stage, where open data about crime occurrences refer to the data disclosed by each police department in its own way. This paper proposes an interactive tool, called D2RCrime, that assists the designer/DBA of relational crime databases to make the correspondence between the relational data and the classes and properties of a crime ontology. The ontology plays the role of a pattern to represent the concepts of crime and report of crime, and is also the interface to publish on-the-fly relational crime data. This correspondence allows the automatic generation of mapping rules between the two representations, what allows for access to relational data from SPARQL. An evaluation of D2RCrime is done with DBA/system analysts who used the tool for establishing correspondences between relational data and the ontology.},
	author = {Tavares, JÃºlio and Santos, Henrique and Furtado, Vasco and Vasconcelos, Eurico},
	month = oct,
	year = {2012},
	pdf = {tavares-d2rcrime-2012.pdf},
	html = {http://ceur-ws.org/Vol-966/},
	bibtex_show = true
}

@inproceedings{santos_contextual_2015,
	address = {Bethlehem, PA, USA},
	title = {Contextual {Data} {Collection} for {Smart} {Cities}},
	abstract = {As part of Smart Cities initiatives, national, regional and local governments all over the globe are under the mandate of being more open regarding how they share their data. Under this mandate, many of these governments are publishing data under the umbrella of open government data, which includes measurement data from city-wide sensor networks. Furthermore, many of these data are published in so-called data portals as documents that may be spreadsheets, comma-separated value (CSV) data files, or plain documents in PDF or Word documents. The sharing of these documents may be a convenient way for the data provider to convey and publish data but it is not the ideal way for data consumers to reuse the data. For example, the problems of reusing the data may range from difficulty  opening a document that is provided in any format that is not plain text, to the actual problem of understanding the meaning of each piece of knowledge inside of the document. Our proposal tackles those challenges by identifying metadata that has been regarded to be relevant for measurement data and providing a schema for this metadata. We further leverage the Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for data collected in urban environments. We discuss the use of HASNetO and the supporting infrastructure to manage both data and metadata in support of the City of Fortaleza, a large metropolitan area in Brazil.},
	booktitle = {Proceedings of the {Sixth} {Workshop} on {Semantics} for {Smarter} {Cities}},
	author = {Santos, Henrique and Furtado, Vasco and Pinheiro, Paulo and McGuinness, Deborah L.},
	month = oct,
	year = {2015},
	pdf = {santos-contextual-2015.pdf},
	html = {http://ceur-ws.org/Vol-1630/},
	bibtex_show = true
}

@inproceedings{pinheiro_human-aware_2015,
	title = {Human-{Aware} {Sensor} {Network} {Ontology}: {Semantic} {Support} for {Empirical} {Data} {Collection}},
	abstract = {Significant efforts have been made to understand and document knowledge related to scientific measurements. Many of those efforts resulted in one or more high-quality ontologies that describe some aspects of scientific measurements, but not in a comprehensive and coherently integrated manner.  For instance, we note that many of these high-quality ontologies are not properly aligned, and more challenging, that they have different and often conflicting concepts and approaches for encoding knowledge about empirical measurements. As a result of this lack of an integrated view, it is often challenging for scientists to determine whether any two scientific measurements were taken in semantically compatible manners, thus making it difficult to decide whether measurements should be analyzed in combination or not. In this paper, we present the Human-Aware Sensor Network Ontology that is a comprehensive alignment and integration of a sensing infrastructure ontology and a provenance ontology. HASNetO has been under development for more than one year, and has been reviewed, shared and used by multiple scientific communities. The ontology has been in use to support the data management of a number of large-scale ecological monitoring activities (observations) and empirical experiments.},
	booktitle = {Proceedings of the 5th {Workshop} on {Linked} {Science}. {Bethlehem}, {PA}, {USA}},
	author = {Pinheiro, Paulo and McGuinness, Deborah L. and Santos, Henrique},
	month = oct,
	year = {2015},
	pdf = {pinheiro-hasneto-2015.pdf},
	html = {http://ceur-ws.org/Vol-1572/},
	bibtex_show = true
}

@article{mcguinness_semantic_2015,
	title = {Semantic {Support} for {Complex} {Ecosystem} {Research} {Environments}},
	volume = {33},
	url = {http://adsabs.harvard.edu/abs/2015AGUFMIN33F..02K},
	abstract = {As ecosystems come under increasing stresses from diverse sources, there is growing interest in research efforts aimed at monitoring, modeling, and improving understanding of ecosystems and protection options. We aimed to provide a semantic infrastructure capable of representing data initially related to one large aquatic ecosystem research effort - the Jefferson project at Lake George. This effort includes significant historical observational data, extensive sensor-based monitoring data, experimental data, as well as model and simulation data covering topics including lake circulation, watershed runoff, lake biome food webs, etc. The initial measurement representation has been centered on monitoring data and related provenance. We developed a human-aware sensor network ontology (HASNetO) that leverages existing ontologies (PROV-O, OBOE, VSTO*) in support of measurement annotations. We explicitly support the human-aware aspects of human sensor deployment and collection activity to help capture key provenance that often is lacking. Our foundational ontology has since been generalized into a family of ontologies and used to create our human-aware data collection infrastructure that now supports the integration of measurement data along with simulation data. Interestingly, we have also utilized the same infrastructure to work with partners who have some more specific needs for specifying the environmental conditions where measurements occur, for example, knowing that an air temperature is not an external air temperature, but of the air temperature when windows are shut and curtains are open. We have also leveraged the same infrastructure to work with partners more interested in modeling smart cities with data feeds more related to people, mobility, environment, and living. We will introduce our human-aware data collection infrastructure, and demonstrate how it uses HASNetO and its supporting SOLR-based search platform to support data integration and semantic browsing. Further we will present learnings from its use in three relatively diverse large ecosystem research efforts and highlight some benefits and challenges related to our semantically-enhanced foundation.},
	urldate = {2016-12-14},
	journal = {AGU Fall Meeting Abstracts},
	author = {McGuinness, Deborah L. and Pinheiro, Paulo and Santos, Henrique and Klawonn, Matthew and Chastain, Katherine},
	month = dec,
	year = {2015},
	html = {https://agu.confex.com/agu/fm15/meetingapp.cgi/Paper/83708},
	bibtex_show = true,
	keywords = {1908 Cyberinfrastructure, 1930 Data and information governance, 1938 Knowledge representation and knowledge bases, 1970 Semantic web and semantic integration, INFORMATICS},
}

@inproceedings{santos_data_2017,
	title = {From {Data} to {City} {Indicators}: {A} {Knowledge} {Graph} for {Supporting} {Automatic} {Generation} of {Dashboards}},
	shorttitle = {From {Data} to {City} {Indicators}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-58451-5_7},
	doi = {10.1007/978-3-319-58451-5_7},
	abstract = {In the context of Smart Cities, indicator definitions have been used to calculate values that enable the comparison among different cities. The calculation of an indicator values has challenges as the calculation may need to combine some aspects of quality while addressing different levels of abstraction. Knowledge graphs (KGs) have been used successfully to support flexible representation, which can support improved understanding and data analysis in similar settings. This paper presents an operational description for a city KG, an indicator ontology that support indicator discovery and data visualization and an application capable of performing metadata analysis to automatically build and display dashboards according to discovered indicators. We describe our implementation in an urban mobility setting.},
	language = {en},
	urldate = {2017-05-20},
	booktitle = {The {Semantic} {Web}},
	publisher = {Springer, Cham},
	author = {Santos, Henrique and Dantas, Victor and Furtado, Vasco and Pinheiro, Paulo and McGuinness, Deborah L.},
	month = may,
	year = {2017},
	pages = {94--108},
	selected={true},
	pdf = {santos-indicators-2017.pdf},
	html = {https://link.springer.com/chapter/10.1007/978-3-319-58451-5_7},
	bibtex_show = true
}

@inproceedings{santos_exploring_2021,
	title = {Exploring and {Analyzing} {Machine} {Commonsense} {Benchmarks}},
	abstract = {Commonsense question-answering (QA) tasks, in the form of benchmarks, are constantly being introduced for challenging and comparing commonsense QA systems. The benchmarks provide question sets that systemsâ developers can use to train and test new models before submitting their implementations to official leaderboards. Although these tasks are created to evaluate systems in identified dimensions (e.g. topic, reasoning type), this metadata is limited and largely presented in an unstructured format or completely not present. Because machine common sense is a fast-paced field, the problem of fully assessing current benchmarks and systems with regards to these evaluation dimensions is aggravated. We argue that the lack of a common vocabulary for aligning these approaches' metadata limits researchers in their efforts to understand systems' deficiencies and in making effective choices for future tasks. In this paper, we first discuss this MCS ecosystem in terms of its elements and their metadata. Then, we present how we are supporting the assessment of approaches by initially focusing on commonsense benchmarks. We describe our initial MCS Benchmark Ontology, an extensible common vocabulary that formalizes benchmark metadata, and showcase how it is supporting the development of a Benchmark tool that enables benchmark exploration and analysis.},
	booktitle = {Proceedings of the {Workshop} on {Common} {Sense} {Knowledge} {Graphs}},
	author = {Santos, Henrique and Gordon, Minor and Liang, Zhicheng and Forbush, Gretchen and McGuinness, Deborah L.},
	year = {2021},
	pdf = {santos-benchmarks-2021.pdf},
	html = {https://usc-isi-i2.github.io/AAAI21workshop/},
	bibtex_show = true
}

@article{rashid_semantic_2020,
	title = {The {Semantic} {Data} {Dictionary} â {An} {Approach} for {Describing} and                     {Annotating} {Data}},
	volume = {2},
	url = {https://doi.org/10.1162/dint_a_00058},
	doi = {10.1162/dint_a_00058},
	abstract = {It is common practice for data providers to include text descriptions for each                     column when publishing data sets in the form of data dictionaries. While these                     documents are useful in helping an end-user properly interpret the meaning of a                     column in a data set, existing data dictionaries typically are not                     machine-readable and do not follow a common specification standard. We introduce                     the Semantic Data Dictionary, a specification that formalizes the assignment of                     a semantic representation of data, enabling standardization and harmonization                     across diverse data sets. In this paper, we present our Semantic Data Dictionary                     work in the context of our work with biomedical data; however, the approach can                     and has been used in a wide range of domains. The rendition of data in this form                     helps promote improved discovery, interoperability, reuse, traceability, and                     reproducibility. We present the associated research and describe how the                     Semantic Data Dictionary can help address existing limitations in the related                     literature. We discuss our approach, present an example by annotating portions                     of the publicly available National Health and Nutrition Examination Survey data                     set, present modeling challenges, and describe the use of this approach in                     sponsored research, including our work on a large National Institutes of Health                     (NIH)-funded exposure and health data portal and in the RPI-IBM collaborative                     Health Empowerment by Analytics, Learning, and Semantics project. We evaluate                     this work in comparison with traditional data dictionaries, mapping languages,                     and data integration tools.},
	number = {4},
	urldate = {2021-03-03},
	journal = {Data Intelligence},
	author = {Rashid, Sabbir M. and McCusker, James P. and Pinheiro, Paulo and Bax, Marcello P. and Santos, Henrique and Stingone, Jeanette A. and Das, Amar K. and McGuinness, Deborah L.},
	month = apr,
	year = {2020},
	note = {Publisher: MIT Press},
	pages = {443--486},
	pdf = {rashid-sdd-2020.pdf},
	html = {https://doi.org/10.1162/dint_a_00058},
	bibtex_show = true
}

@inproceedings{santos_semantic_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Semantic} {Framework} for {Enabling} {Radio} {Spectrum} {Policy} {Management} and {Evaluation}},
	isbn = {978-3-030-62466-8},
	doi = {10.1007/978-3-030-62466-8_30},
	abstract = {Because radio spectrum is a finite resource, its usage and sharing is regulated by government agencies. These agencies define policies to manage spectrum allocation and assignment across multiple organizations, systems, and devices. With more portions of the radio spectrum being licensed for commercial use, the importance of providing an increased level of automation when evaluating such policies becomes crucial for the efficiency and efficacy of spectrum management. We introduce our Dynamic Spectrum Access Policy Framework for supporting the United States governmentâs mission to enable both federal and non-federal entities to compatibly utilize available spectrum. The DSA Policy Framework acts as a machine-readable policy repository providing policy management features and spectrum access request evaluation. The framework utilizes a novel policy representation using OWL and PROV-O along with a domain-specific reasoning implementation that mixes GeoSPARQL, OWL reasoning, and knowledge graph traversal to evaluate incoming spectrum access requests and explain how applicable policies were used. The framework is currently being used to support live, over-the-air field exercises involving a diverse set of federal and commercial radios, as a component of a prototype spectrum management system.},
	language = {en},
	booktitle = {The {Semantic} {Web} â {ISWC} 2020},
	publisher = {Springer International Publishing},
	author = {Santos, Henrique and Mulvehill, Alice and Erickson, John S. and McCusker, James P. and Gordon, Minor and Xie, Owen and Stouffer, Samuel and Capraro, Gerard and Pidwerbetsky, Alex and Burgess, John and Berlinsky, Allan and Turck, Kurt and Ashdown, Jonathan and McGuinness, Deborah L.},
	editor = {Pan, Jeff Z. and Tamma, Valentina and dâAmato, Claudia and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
	year = {2020},
	keywords = {Dynamic spectrum access, Policies, Reasoning},
	pages = {482--498},
	selected={true},
	pdf = {santos-dsa-2020.pdf},
	html = {https://link.springer.com/chapter/10.1007/978-3-030-62466-8_30},
	bibtex_show = true
}

@inproceedings{pinheiro_annotating_2018,
	title = {Annotating {Diverse} {Scientific} {Data} with {HAScO}},
	abstract = {Ontologies are being widely used across many scientific fields, most notably in roles related to acquiring, preparing, integrating and managing data resources. Data acquisition and preparation activities are  often difficult to reuse since they tend to be domain dependent, as well as dependent on how data is acquired: through measurement, subject-elicitation, and/or model-gen{\textbackslash}-er{\textbackslash}-ation activities. Therefore, tools developed for preparing data from one scientific activity often cannot be easily adapted to prepare data from other scientific activities. We introduce the Human-Aware Science Ontology (HAScO) that integrates a collection of well-established science-related ontologies, and aims to address issues related to data annotation for large data ecosystem, where data can come from diverse
data sources including sensors, lab results, and questionnaires. The work reported in the paper is based on our experience developing HAScO, using it to annotate data collections to facilitate data exploration and analysis for numerous scientific projects, three of which will be described. Data files produced by scientific studies are processed to identify and annotate the objects (a gene, for instance) with the appropriate ontological terms. One benefit we realized (of preserving scientific data provenance) is that
software platforms can support scientists in their exploration and preparation of data for analysis since the meaning of and interrelationships between the data is explicit.},
	booktitle = {Proceedings of the {Seminar} on {Ontology} {Research} in {Brazil} 2018 ({ONTOBRAS} 2018). {SÃ£o} {Paulo}, {SP}, {Brazil}},
	author = {Pinheiro, Paulo and Bax, Marcello and Santos, Henrique and Rashid, Sabbir M. and Liang, Zhicheng and Liu, Yue and McCusker, James P. and McGuinness, Deborah L.},
	year = {2018},
	pdf = {pinheiro-hasco-2018.pdf},
	html = {http://ceur-ws.org/Vol-2228/},
	bibtex_show = true
}

@inproceedings{pinheiro_hadatac:_2018,
	title = {{HADatAc}: {A} {Framework} for {Scientific} {Data} {Integration} using {Ontologies}},
	abstract = {To investigate the cause and progression of a phenomenon, such as chronic disease, 
it is essential to collect a wide variety of data that together explains the complex interplay of different factors, e.g., genetic, lifestyle, environmental and social. Sharing information between studies is therefore of paramount importance. However, data that needs to be analyzed must be appropriately integrated, conceptually aligned, and harmonized. This implies that data collection must be done either in a sufficiently similar or a sufficiently transparent way in order to support meaningful synthesis from different studies. We will demonstrate how the Human-Aware Data Acquisition (HADatAc) framework integrates and harmonizes data from multiple scientific studies and thus how to use it in interdisciplinary science investigations.},
	booktitle = {Proceedings of the {ISWC} {Posters} \& {Demonstrations} {Track}},
	author = {Pinheiro, Paulo and Santos, Henrique and Liang, Zhicheng and Liu, Yue and Rashid, Sabbir M. and McGuinness, Deborah L. and Bax, Marcello P.},
	year = {2018},
	pdf = {pinheiro-hadatac-2018.pdf},
	html = {http://ceur-ws.org/Vol-2180/},
	bibtex_show = true
}

@article{santos_experimental_2021,
	title = {An experimental study measuring human annotator categorization agreement on commonsense sentences},
	volume = {2},
	issn = {2516-712X},
	url = {https://www.cambridge.org/core/journals/experimental-results/article/an-experimental-study-measuring-human-annotator-categorization-agreement-on-commonsense-sentences/8CC52DFFE4EBF5013638ECC03557D5BA},
	doi = {10.1017/exp.2021.9},
	abstract = {Developing agents capable of commonsense reasoning is an important goal in Artificial Intelligence (AI) research. Because commonsense is broadly defined, a computational theory that can formally categorize the various kinds of commonsense knowledge is critical for enabling fundamental research in this area. In a recent book, Gordon and Hobbs described such a categorization, argued to be reasonably complete. However, the theoryâs reliability has not been independently evaluated through human annotator judgments. This paper describes such an experimental study, whereby annotations were elicited across a subset of eight foundational categories proposed in the original Gordon-Hobbs theory. We avoid bias by eliciting annotations on 200 sentences from a commonsense benchmark dataset independently developed by an external organization. The results show that, while humans agree on relatively concrete categories like time and space, they disagree on more abstract concepts. The implications of these findings are briefly discussed.},
	language = {en},
	urldate = {2021-06-29},
	journal = {Experimental Results},
	author = {Santos, Henrique and Kejriwal, Mayank and Mulvehill, Alice M. and Forbush, Gretchen and McGuinness, Deborah L.},
	editor = {Rivera, AdÃ­n RamÃ­rez},
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {annotation, annotator agreement, benchmarking, Commonsense reasoning, commonsense theories},
	selected={true},
	pdf = {santos-annotation-2021.pdf},
	html = {https://www.cambridge.org/core/journals/experimental-results/article/an-experimental-study-measuring-human-annotator-categorization-agreement-on-commonsense-sentences/8CC52DFFE4EBF5013638ECC03557D5BA},
	bibtex_show = true
}

@inproceedings{santos_service-oriented_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Service}-{Oriented} {Architecture} for {Assisting} the {Authoring} of {Semantic} {Crowd} {Maps}},
	isbn = {978-3-642-34459-6},
	doi = {10.1007/978-3-642-34459-6_4},
	abstract = {Although there are increasingly more initiatives for the generation of semantic knowledge based on user participation, there is still a shortage of platforms for regular users to create applications on which semantic data can be exploited and generated automatically. We propose an architecture, called Semantic Maps (SeMaps), for assisting the authoring and hosting of applications in which the maps combine the aggregation of a Geographic Information System and crowd-generated content (called here crowd maps). In these systems, the digital map works as a blackboard for accommodating stories told by people about events they want to share with others typically participating in their social networks. SeMaps offers an environment for the creation and maintenance of sites based on crowd maps with the possibility for the user to characterize semantically that which s/he intends to mark on the map. The designer of a crowd map, by informing a linguistic expression that designates what has to be marked on the maps, is guided in a process that aims to associate a concept from a common-sense base to this linguistic expression. Thus, the crowd maps start to have dominion over common-sense inferential relations that define the meaning of the marker, and are able to make inferences about the network of linked data. This makes it possible to generate maps that have the power to perform inferences and access external sources (such as DBpedia) that constitute information that is useful and appropriate to the context of the map. In this paper we describe the architecture of SeMaps and how it was applied in a crowd map authoring tool.},
	language = {en},
	booktitle = {Advances in {Artificial} {Intelligence} - {SBIA} 2012},
	publisher = {Springer},
	author = {Santos, Henrique and Furtado, Vasco},
	editor = {Barros, Leliane N. and Finger, Marcelo and Pozo, Aurora T. and GimenÃ©nez-Lugo, Gustavo A. and Castilho, Marcos},
	year = {2012},
	keywords = {Authoring Tool, Geographic Information System, Linguistic Expression, Semantic Data, User Participation},
	pages = {32--41},
	pdf = {santos-semaps-2012.pdf},
	html = {https://link.springer.com/chapter/10.1007/978-3-642-34459-6_4},
	bibtex_show = true
}

@article{furtado_open_2012,
	title = {Open {Government} and {Citizen} {Participation} in {Law} {Enforcement} via {Crowd} {Mapping}},
	volume = {27},
	issn = {1941-1294},
	doi = {10.1109/MIS.2012.80},
	abstract = {The authors describe WikiCrimes, a project founded on a website of the same name that aims to offer a common interaction space for the general public where they can note criminal activity and track the locations where such crimes occur. The goal is to encourage collaborative participation that generates useful information for everyone. The authors describe their experience with WikiCrimes, emphasizing the services it provides to citizens and underlining some of the problems they've overcome to date. Their ultimate goal is to help establish a research agenda about the topic by inviting the academic community to embrace WikiCrimes as a platform that bridges citizen participation and open government.},
	number = {4},
	journal = {IEEE Intelligent Systems},
	author = {Furtado, Vasco and Caminha, Carlos and Ayres, Leonardo and Santos, Henrique},
	month = jul,
	year = {2012},
	note = {Conference Name: IEEE Intelligent Systems},
	keywords = {Context awareness, crowd map, Government, Internet, knowledge engineering, knowledge management, Knowledge management, law enforcement, Law enforcement, Ontologies, Social network services, Weapons},
	pages = {63--69},
	pdf = {furtado-open-2012.pdf},
	html = {https://ieeexplore.ieee.org/abstract/document/6285930},
	bibtex_show = true
}

@inproceedings{santos_widgets_2011,
	title = {Widgets baseados em conhecimento advindo de dados referenciados e abertos na {Web}},
	copyright = {Copyright (c)},
	url = {https://sol.sbc.org.br/index.php/webmedia/article/view/5597},
	abstract = {The use of widgets is a very popular manner to make a website customization. From widgetâs creation the content creator configures the website with functions that he/she consider adequate to the users. Typically, widgets relies on syndication (RSS) in which a website content is made available to other websites. Even though there is a huge popularity of this kind of widgets, they typically are constrained to what a data provider makes available. Linked Open Data (LOD) is an opportunity to cope with the todayâs constraint in the process of widget creation and execution. We propose a platform, called SemWidgets (from Semantic Widgets), for the creation and execution of piece of programs able to access and reason over LOD. With SemWidgets, we provide to the content producer of a website a way to describe the concept(s) that best represent the content to be explored. Widgets created from SemWidgets have the power to perform inferences and access external sources that constitute information that may be useful and appropriate to the context of the website.},
	language = {pt},
	urldate = {2021-06-29},
	booktitle = {Anais do {SimpÃ³sio} {Brasileiro} de {Sistemas} {MultimÃ­dia} e {Web} ({WebMedia})},
	publisher = {SBC},
	author = {Santos, Henrique and Furtado, Vasco and Pinheiro, VlÃ¡dia and Ferreira, Caio and Vasconcelos, JosÃ© Eurico and Shiki, Guilherme},
	month = oct,
	year = {2011},
	pages = {43--46},
	pdf = {santos-widgets-2011.pdf},
	html = {https://sol.sbc.org.br/index.php/webmedia/article/view/5597},
	bibtex_show = true
}

@inproceedings{santos_dynamic_2020,
	title = {The {Dynamic} {Spectrum} {Access} {Policy} {Framework} in {Action}},
	abstract = {Because radio spectrum is a finite resource, its usage and sharing is regulated by government agencies through policies that manage spectrum allocation. With more portions of the spectrum being licensed for commercial use, the importance of providing an increased level of automation when evaluating such policies becomes crucial for the efficiency and efficacy of spectrum management. This poster showcases the Dynamic Spectrum Access Policy Framework, which acts as a machine-readable policy repository providing policy management features and spectrum access request evaluation. It includes the use of the framework's policy management capabilities to create and modify policies in a novel policy representation using two recommended web standards (OWL and PROV-O), and the request evaluation engine to verify the assignment of permit/deny effects to spectrum requests.},
	booktitle = {{ISWC} 2020 {Posters}, {Demos}, and {Industry} {Tracks}},
	author = {Santos, Henrique and Mulvehill, Alice M. and Erickson, John S. and McCusker, James P. and Gordon, Minor and Xie, Owen and Stouffer, Samuel and Capraro, Gerard and Pidwerbetsky, Alex and Burgess, John and Berlinsky, Allan and Turck, Kurt and Ashdown, Jonathan and McGuinness, Deborah L.},
	year = {2020},
	pdf = {santos-dsa-poster-2020.pdf},
	html = {http://ceur-ws.org/Vol-2721/},
	bibtex_show = true
}

@inproceedings{santos_geospatial_2021,
	title = {Geospatial {Reasoning} with {Shapefiles} for {Supporting} {Policy} {Decisions}},
	abstract = {Policies are authoritative assets that are present in multiple domains to support decision-making. They describe what actions are allowed or recommended when domain entities and their attributes satisfy certain criteria. It is common to find policies that contain geographical rules, including distance and containment relationships among named locations. These locations' polygons can often be found encoded in geospatial datasets. We present an approach to transform data from geospatial datasets into Linked Data using the OWL, PROV-O, and GeoSPARQL standards, and to leverage this representation to support automated ontology-based policy decisions. We applied our approach to location-sensitive radio spectrum policies to identify relationships between radio transmitters coordinates and policy-regulated regions in Census.gov datasets. Using a policy evaluation pipeline that mixes OWL reasoning and GeoSPARQL, our approach implements the relevant geospatial relationships, according to a set of requirements elicited by radio spectrum domain experts.},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {Geospatial} {Linked} {Data} ({GeoLD} 2021)},
	author = {Santos, Henrique and McCusker, James P. and McGuinness, Deborah L.},
	year = {2021},
	pdf = {santos-geospatial-2021.pdf},
	bibtex_show = true
}

@inproceedings{falkow_towards_2021,
	title = {Towards a {Domain}-{Agnostic} {Computable} {Policy} {Tool}},
	abstract = {Policies are often crucial for decision-making in a wide range of domains. Typically they are written in natural language, which leaves room for different individual interpretations. In contrast, computable policies offer standardization for the structures that encode information, which can help decrease ambiguity and variability of interpretations. Sadly, the majority of computable policy frameworks are domain-specific or require tailored customization, limiting potential applications of this technology. For this reason, we propose ADAPT, a domain-agnostic policy tool that leverages domain knowledge, expressed in knowledge graphs, and employs W3C standards in semantics and provenance to enable the construction, visualization, and management of computable policies that include domain knowledge to reduce terminology inconsistencies, and augment the policy evaluation process.},
	booktitle = {{ESWC} 2021 {Posters} \& {Demos} {Track}},
	author = {Falkow, Mitchell and Santos, Henrique and McGuinness, Deborah L.},
	year = {2021},
	pdf = {falkow-tool-2021.pdf},
	bibtex_show = true
}

@inproceedings{santos_enabling_2017,
	address = {Vienna, Austria},
	title = {Enabling {Data} {Analytics} from {Knowledge} {Graphs}},
	abstract = {Scientific data is being acquired in high volumes in support of studies in many knowledge areas. Regular data analytics processes make use of datasets that often lack enough knowledge to facilitate the work of data scientists. By relying on knowledge graphs (KGs), those difficulties can be mitigated. This research focuses on enabling data analytics over scientific data in light of knowledge available in KGs, providing access, based on queries, to scientific data points in KGs to data users while making use of available knowledge to facilitate their data analytics activities.},
	booktitle = {Proceedings of the {Doctoral} {Consortium} at the 16th {International} {Semantic} {Web} {Conference} ({ISWC} 2017)},
	author = {Santos, Henrique},
	year = {2017},
	pdf = {santos-enabling-2017.pdf},
	html = {http://ceur-ws.org/Vol-1962/},
	bibtex_show = true
}
