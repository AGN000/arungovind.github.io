---
---

@inproceedings{Cadaver,
abbr={CHI},
author = {Harvey, Emma and Sandhaus, Hauke and Jacobs, Abigail Z. and Moss, Emanuel and Sloane, Mona},
title = {The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology},
year = {2024},
isbn = {},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3613904.3642004},
doi = {},
abstract = {Motion capture systems, used across various domains, make body representations concrete through technical processes. We argue that the measurement of bodies and the validation of measurements for motion capture systems can be understood as social practices. By analyzing the findings of a systematic literature review (N=278) through the lens of social practice theory, we show how these practices, and their varying attention to errors, become ingrained in motion capture design and innovation over time. Moreover, we show how contemporary motion capture systems perpetuate assumptions about human bodies and their movements. We suggest that social practices of measurement and validation are ubiquitous in the development of data- and sensor-driven systems more broadly, and provide this work as a basis for investigating hidden design assumptions and their potential negative consequences in human-computer interaction.},
booktitle = {2024 ACM CHI Conference on Human Factors in Computing Systems},
pages = {},
numpages = {},
keywords = {motion capture, measurement, validation, social practices, anthropometry},
location = {},
series = {CHI '24}, 
html = {https://dl.acm.org/doi/10.1145/3613904.3642004}, 
selected = {true}
}

@inproceedings{WATA,
abbr={FAccT},
author = {Costanza-Chock, Sasha and Harvey, Emma and Raji, Inioluwa Deborah and Czernuszenko, Martha and Buolamwini, Joy},
title = {Who Audits the Auditors? Recommendations from a Field Scan of the Algorithmic Auditing Ecosystem},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://arxiv.org/abs/2310.02521},
doi = {10.1145/3531146.3533213},
abstract = {Algorithmic audits (or ‘AI audits’) are an increasingly popular mechanism for algorithmic accountability; however, they remain poorly defined. Without a clear understanding of audit practices, let alone widely used standards or regulatory guidance, claims that an AI product or system has been audited, whether by first-, second-, or third-party auditors, are difficult to verify and may potentially exacerbate, rather than mitigate, bias and harm. To address this knowledge gap, we provide the first comprehensive field scan of the AI audit ecosystem. We share a catalog of individuals (N=438) and organizations (N=189) who engage in algorithmic audits or whose work is directly relevant to algorithmic audits; conduct an anonymous survey of the group (N=152); and interview industry leaders (N=10). We identify emerging best practices as well as methods and tools that are becoming commonplace, and enumerate common barriers to leveraging algorithmic audits as effective accountability mechanisms. We outline policy recommendations to improve the quality and impact of these audits, and highlight proposals with wide support from algorithmic auditors as well as areas of debate. Our recommendations have implications for lawmakers, regulators, internal company policymakers, and standards-setting bodies, as well as for auditors. They are: 1) require the owners and operators of AI systems to engage in independent algorithmic audits against clearly defined standards; 2) notify individuals when they are subject to algorithmic decision-making systems; 3) mandate disclosure of key components of audit findings for peer review; 4) consider real-world harm in the audit process, including through standardized harm incident reporting and response mechanisms; 5) directly involve the stakeholders most likely to be harmed by AI systems in the algorithmic audit process; and 6) formalize evaluation and, potentially, accreditation of algorithmic auditors.},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1571–1583},
numpages = {13},
keywords = {ethical AI, AI audit, audit, algorithmic accountability, AI bias, algorithm audit, AI policy, AI harm},
location = {Seoul, Republic of Korea},
series = {FAccT '22}, 
html = {https://arxiv.org/abs/2310.02521}, 
selected = {true}
}

% preview={hm_icon.jpg},
% pdf={example_pdf.pdf},
% altmetric={248277},
% dimensions={true},

