---
---

@string{aps = {American Physical Society,}}

@article{talat2022you,
  abbr={ACL Workshop},
  title={You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings},
  author={Zeerak Talat and Aur{\'e}lie N{\'e}v{\'e}ol and Stella Biderman and Miruna Clinciu and Manan Dey and Shayne Longpre and Sasha Luccioni and Maraim Masoud and Margaret Mitchell and Dragomir Radev and Shanya Sharma and Arjun Subramonian and Jaesung Tae and Samson Tan and Deepak Tunuguntla and Oskar van der Wal},
  abstract={Evaluating bias, fairness, and social impact in monolingual language models is a difficult task. This challenge is further compounded when language modeling occurs in a multilingual context. Considering the implication of evaluation biases for large multilingual language models, we situate the discussion of bias evaluation within a wider context of social scientific research with computational work. We highlight three dimensions of developing multilingual bias evaluation frameworks: (1) increasing transparency through documentation, (2) expanding targets of bias beyond gender, and (3) addressing cultural differences that exist between languages. We further discuss the power dynamics and consequences of training large language models and recommend that researchers remain cognizant of the ramifications of developing such technologies.},
  journal={Challenges & Perspectives in Creating Large Language Models workshop at ACL,},
  publisher={Challenges & Perspectives in Creating Large Language Models workshop at ACL},
  year={2022},
  url={https://openreview.net/forum?id=rK-7NhfSIW5},
  html={https://openreview.net/forum?id=rK-7NhfSIW5},
  pdf={bigscience_bias.pdf},
}

@article{sanh2022multitask,
  abbr={ICLR},
  title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
  author={Victor Sanh and Albert Webson and Colin Raffel and Stephen Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Teven Le Scao and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M Rush},
  abstract={Large language models have recently been shown to attain reasonable zero-shot generalization on a diverse set of tasks (Brown  et  al.,  2020). It has been hypothesized that this is a consequence of implicit multitask learning in language model training (Radford et al., 2019). Can zero-shot generalization instead be directly induced by explicit multitask learning? To test this question at scale, we develop a system for easily mapping general natural language tasks into a human-readable prompted form. We convert a large set of supervised datasets,  each with multiple prompts using varying natural language. These prompted datasets allow for benchmarking the ability of a model  to  perform  completely  unseen tasks  specified in natural language.  We fine-tune a pretrained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a wide variety of tasks. The model attains strong zero-shot performance onseveral  datasets,  often  outperforming  models 16× its size.  Further, our model attains strong performance on a subset of tasks from the BIG-Bench benchmark, out-performing models 6× its size.},
  journal={International Conference on Learning Representations (Spotlight),},
  publisher={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=9Vrb9D0WI4},
  html={https://openreview.net/forum?id=9Vrb9D0WI4},
  pdf={T0.pdf},
  selected={true}
}

@article{bach2022promptsource,
  abbr={ACL Demo Track},
  title={PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts},
  author={Stephen H. Bach and Victor Sanh and Zheng-Xin Yong and Albert Webson and Colin Raffel and Nihal V. Nayak and Abheesht Sharma and Taewoon Kim and M Saiful Bari and Thibault Fevry and Zaid Alyafeai and Manan Dey and Andrea Santilli and Zhiqing Sun and Srulik Ben-David and Canwen Xu and Gunjan Chhablani and Han Wang and Jason Alan Fries and Maged S. Al-shaibani and Shanya Sharma and Urmish Thakker and Khalid Almubarak and Xiangru Tang and Xiangru Tang and Mike Tian-Jian Jiang and Alexander M. Rush},
  abstract={PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource.},
  journal={60th Annual Meeting of the Association for Computational Linguistics (ACL), Demo Track,},
  publisher={60th Annual Meeting of the Association for Computational Linguistics (ACL), Demo Track, 2022},
  year={2022},
  url={https://arxiv.org/abs/2202.01279},
  html={https://arxiv.org/abs/2202.01279},
  pdf={promptsource.pdf}
}

@article{mielke2021words,
  abbr={arXiv},
  title={Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP},
  author={Sabrina J. Mielke and Zaid Alyafeai and Elizabeth Salesky and Colin Raffel and Manan Dey and Matthias Gallé and Arun Raja and Chenglei Si and Wilson Y. Lee and Benoît Sagot and Samson Tan},
  abstract={What are the units of text that we want to model? From bytes to multi-word expressions, text can be analyzed and generated at many granularities. Until recently, most natural language processing (NLP) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (BPE), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. Is the end of the road character-level model or byte-level processing? In this survey, we connect several lines of work from the pre-neural and neural era, by showing how hybrid approaches of words and characters as well as subword-based approaches based on learned segmentation have been proposed and evaluated. We conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications.},
  journal={arXiv:2112.10508,},
  publisher={arXiv:2112.10508},
  year={2021},
  url={https://arxiv.org/abs/2112.10508},
  html={https://arxiv.org/abs/2112.10508},
  pdf={tokenization.pdf}
}

@article{sharma2021evaluating,
  abbr={NeurIPS DCS},
  title={Evaluating Gender Bias in Natural Language Inference},
  author={Shanya Sharma and Manan Dey and Koustuv Sinha},
  abstract={Gender-bias stereotypes have recently raised significant ethical concerns in natural language processing. However, progress in detection and evaluation of gender bias in natural language understanding through inference is limited and requires further investigation. In this work, we propose an evaluation methodology to measure these biases by constructing a challenge task that involves pairing gender-neutral premises against a gender-specific hypothesis. We use our challenge task to investigate state-of-the-art NLI models on the presence of gender stereotypes using occupations. Our findings suggest that three models (BERT, RoBERTa, BART) trained on MNLI and SNLI datasets are significantly prone to gender-induced prediction errors. We also find that debiasing techniques such as augmenting the training dataset to ensure a gender-balanced dataset can help reduce such bias in certain cases.},
  journal={Workshop on Dataset Curation and Security at NeurIPS,},
  publisher={NeurIPS 2020 Workshop on Dataset Curation and Security},
  year={2020},
  url={http://securedata.lol/camera_ready/19.pdf},
  html={http://securedata.lol/camera_ready/19.pdf},
  pdf={gender_bias_nli.pdf}
}

@article{sharma2020assessing,
  abbr={NeurIPS AI4SG},
  title={Assessing Viewer's Mental Health by Detecting Depression in YouTube Videos},
  author={Shanya Sharma and Manan Dey},
  abstract={Depression is one of the most prevalent mental health issues around the world, proving to be one of the leading causes of suicide and placing large economic burdens on families and society. In this paper, we develop and test the efficacy of machine learning techniques applied to the content of YouTube videos captured through their transcripts and determine if the videos are depressive or have a depressing trigger. Our model can detect depressive videos with an accuracy of 83%. We also introduce a real-life evaluation technique to validate our classification based on the comments posted on a video by calculating the CES-D scores of the comments. This work conforms greatly with the UN Sustainable Goal of ensuring Good Health and Well Being with major conformity with section UN SDG 3.4.},
  journal={AI for Social Good workshop at NeurIPS,},
  publisher={AI for Social Good workshop at NeurIPS},
  year={2019},
  url={https://aiforsocialgood.github.io/neurips2019/accepted/track1/pdfs/52_aisg_neurips2019.pdf},
  html={https://aiforsocialgood.github.io/neurips2019/accepted/track1/pdfs/52_aisg_neurips2019.pdf},
  pdf={depression.pdf}
}