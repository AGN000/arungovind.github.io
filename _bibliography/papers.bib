@ARTICLE{9828394,
  author={Nigam, Nitika and Dutta, Tanima},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Emotion and Gesture Guided Action Recognition in Videos Using Supervised Deep Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-11},
  doi={10.1109/TCSS.2022.3187198}}

@ARTICLE{9731518,
  author={Nigam, Nitika and Dutta, Tanima and Verma, Deepali},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Fall-perceived Action Recognition of Persons with Neurological Disorders using Semantic Supervision}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TCDS.2022.3157813}}

@ARTICLE{9393944,
  author={Nigam, Nitika and Dutta, Tanima and Gupta, Hari Prabhat},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={FactorNet: Holistic Actor, Object, and Scene Factorization for Action Recognition in Videos}, 
  year={2022},
  volume={32},
  number={3},
  pages={976-991},
  doi={10.1109/TCSVT.2021.3070688}}
  
  @ARTICLE{9568769,
  author={Bagi, Randheer and Dutta, Tanima and Nigam, Nitika and Verma, Deepali and Gupta, Hari Prabhat},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Met-MLTS: Leveraging Smartphones for End-to-End Spotting of Multilingual Oriented Scene Texts and Traffic Signs in Adverse Meteorological Conditions}, 
  year={2022},
  volume={23},
  number={8},
  pages={12801-12810},
  doi={10.1109/TITS.2021.3117793}}
  
  @ARTICLE{9733381,
  author={Soni, Aishwarya and Dutta, Tanima and Nigam, Nitika and Verma, Deepali and Gupta, Hari Prabhat},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Supervised Attention Network for Arbitrary-Shaped Text Detection in Edge-Fainted Noisy Scene Images}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/TCSS.2022.3153557}}
   
@inproceedings{10.1145/3563357.3567753,
author = {Nigam, Nitika and Dutta, Tanima},
title = {Crowd Crush Detection in Large Mass Gatherings via Federated Learning across Multicamera Environment: Poster Abstract},
year = {2022},
url = {https://doi.org/10.1145/3563357.3567753},
doi = {10.1145/3563357.3567753},
abstract = {Crowd crush in mass gatherings during large events are more frequent nowadays. It may get threatening quickly and even cause the death of many. Single camera surveillance is not efficient in large events spreading over wide areas. In multicamera surveillance environment, the centralized decision may not be favourable due to solitude and safety concerns. Moreover, existing neural networks need a large amount of training data for accurate detection. This paper proposes a low-cost system that uses a federated learning setup with light-weight model to reduce overheads during training and protect crowd privacy. We introduce a new loss function, denoted by contrastive focal loss, to reduce false positives and organize overcrowded regions in minimal time. We collect crowd crush and stampede videos to create a new annotated dataset, named as CrowdStampede. We achieve good results under different data distribution settings.},
booktitle = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {297â€“298},
}
  

