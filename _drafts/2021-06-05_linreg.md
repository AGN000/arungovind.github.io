---
layout: distill
title: Bayesian linear regression
description: an example of a distill-style blog post and main elements
date: 2021-06-05

authors:
  - name: Vitalii Urbanevych
    # url: "https://en.wikipedia.org/wiki/Albert_Einstein"
    # affiliations:
    #   name: IAS, Princeton

bibliography: 2021-06-05_linreg.bib
---

**NOTE:**
This is just my interpretetion of the material from <d-cite key="bishop_pattern"></d-cite>.


## Linear regression

Assume that we have a target variable $t$:

\begin{equation}
  t = y(\mathbf{x}, \mathbf{w}) + \epsilon
  \label{model}
\end{equation}

The function $y(\mathbf{x}, \mathbf{w})$ defines our model as **x** is a data and **w**
is a paremeters vector. Formally this function is defined as:

\begin{equation}
  y(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \mathbf{\phi}(\mathbf{x}),
  \label{basfunc}
\end{equation}

where $\mathbf{\phi}(\mathbf{x})$ is a set of basis functions with a dummy zero component
$\phi_0(\mathbf{x}) = 1$. These functions can belong to a different families(for example Gaussian
or sigmoid functions), but in all that cases the model will be called *linear regression*
as it will be linear with respect to $\mathbf{w}$. We will regard only the simplest choice of basis functions where $y(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \mathbf{x}$.

In Eq.\ref{model} $\epsilon$ defines a random Gaussian noise with a zero mean and precision
$\beta$. So we can write

\begin{equation}
  p (t \mid \mathbf{x}, \mathbf{w}, \beta) = N(t \mid y(\mathbf{x}, \mathbf{w}), \beta^{-1})
  \label{norm}
\end{equation}

and corresponding likelihood function is


\begin{equation}
  p (\mathbf{t} \mid \mathbf{X}, \mathbf{w}, \beta) = \prod_{i=1}^N N(t_i \mid y(\mathbf{x}_i, \mathbf{w}), \beta^{-1}),
  \label{likelihood}
\end{equation}

where $\mathbf{X}$ is a vector of inputs $(\mathbf{x}_1, \mathbf{x}_2,...,\mathbf{x}_N)$ and $\mathbf{t}$ is a vector of target points
$\mathbf{t} = (t_1, t_2,..., t_N)$.

<!-- Maximizing \ref{likelihood} with respect to $\mathbf{w}$ we obain an expression: -->

## Bayesian regression

