---
layout: page
permalink: /join-us/students/
title: Student Assistants and Theses
description: 
nav: false
nav_order: 21
---

**Come talk to us!** We have many interesting [projects and problem settings](/projects).
Also, if you have **your own project ideas**, don't hesitate to contact us!
We will support you as best as we can!

At the moment, we offer the following topics for a master's thesis:

## Learning Representations of Medical Data with Autoencoders

Medical data usually comprises a lot of features per sample, often distributed across multiple data modalities. Therefore, it becomes necessary to reduce the data's dimensionality to keep noise and model complexity minimal. Autoencoders are a powerful unsupervised learning tool to find efficient encodings. In this project, autoencoders will be applied to high-dimensional multiomics and imaging data to convert them into meaningful fingerprints.

## Integration and Extraction of Background Knowledge with Large Language Models

At least since ChatGPT, everyone has heard of transformer-based Large Language Models (LLM). This project investigates, how LLMs can be utilized in an eXplainable Artificial Intelligence (XAI) context to integrate/extract background knowledge. Here, background knowledge could for example refer to the intuitive understanding of the problem by a human expert. One suitable approach is given by Knowledge Graphs, which excel at storing structured information.

## Subgroup Discovery in Medical Data

In data mining, subgroup discovery refers to finding interesting subsets within the whole data set with regard to a certain property. In a medical context, a simple (but interpretable) disease prediction model might for example perform mediocre on the overall population, but achieve excellent accuracy on a patient subgroup. Discovering those subgroups would enable the exploitation of simple models for subsets of the population. Subgroup discovery is also related to fairness since a disease prediction model is expected to perform equally well for each patient.

## Clustering of Immune Data

The objective of this project is to find interesting relationships within immunomic data with regard to three axes: horizontal (between features), vertical (between subjects/groups of subjects), and temporal (over time).

## Virtual Reality-based Bibliographic Management

The "method of loci", also known as the "mind palace technique", is a mnemonic device to enhance the recall of information via familiar spatial environments. This project proposes a Virtual Reality-based application for bibliographic management, where scientific papers can be placed and organized in a virtual environment. Another goal is the integration of existing reference management software like Zotero.

## Extraction of traditional flow/mass cytology gates from machine learning models

Flow cytometry and mass cytometry (CyTOF) allow the measurement of multiple biological markers across thousands of cells within each sample. The traditional analysis of single-cell data includes a process referred to as gating, where a domain expert draws a sequence of bounding boxes around cell clusters of interest in 2d plots. Since this procedure is time-consuming and depends on the expert's experience, automatic computation methods have been proposed. However, many machine learning models are hard to interpret, especially for non-domain experts. Therefore, the objective of this project is to extract the traditional gates (bounding boxes) from a trained machine learning model.

## Qualitative Comparison of Attention Maps and Feature Attribution Maps

Since complex Deep Learning models are hard to interpret and regarded as a black box even by domain experts, multiple post-hoc interpretation methods have been proposed. For vision-based models, those methods are often generally referred to as Saliency Maps, which compute a heatmap of importance over the pixel space. Transformer-based models utilize the attention mechanism, where the model learns the relevance of the input features during training. This project aims to compare attribution maps of post-hoc interpretation maps with attention maps from transformer-based models and investigate their theoretical relationship.
